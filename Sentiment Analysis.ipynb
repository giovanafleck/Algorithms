{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Lots of libraries exist that will do sentiment analysis for you. Imagine that: just taking a sentence, throwing it into a library, and geting back a score! How convenient!\n",
    "\n",
    "It's also **totally irresponsible** unless you know how the sentiment analyzer was built. In this homework we're going to see how sentiment analysis is done with a few packages.\n",
    "\n",
    "## Installation\n",
    "\n",
    "If you haven't already, you'll want to `pip install` two packages: NLTK and Textblob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "# !pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK: Natural Language Tooklit\n",
    "\n",
    "[Natural Language Toolkit](https://www.nltk.org/) is the basis for a lot of text analysis done in Python. It's old and terrible and slow, but it's just been used for so long and does so many things that it's generally the default when people get into text analysis. The new kid on the block is [spaCy](https://spacy.io/) (but it doesn't do sentiment analysis so we're leaving it out of this).\n",
    "\n",
    "When you first run NLTK, you need to download some datasets to make sure it will be able to do everything you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/giovanafleck/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/giovanafleck/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/giovanafleck/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do sentiment analysis with NLTK, it only takes a couple lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.153, 'neu': 0.688, 'pos': 0.159, 'compound': 0.0276}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "sia = SIA()\n",
    "sia.polarity_scores(\"This restaurant was great, but I'm not sure if I'll go there again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asking `SentimentIntensityAnalyzer` for the `polarity_score` gave us four values in a dictionary:\n",
    "\n",
    "- **negative:** the negative sentiment in a sentence\n",
    "- **neutral:** the neutral sentiment in a sentence\n",
    "- **positive:** the postivie sentiment in the sentence\n",
    "- **compound:** the aggregated sentiment. \n",
    "    \n",
    "Seems simple enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I just got a call from my boss - does he realise it's Saturday?\"\n",
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in real life, if you use an emoji you can be read as being more positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.786, 'pos': 0.214, 'compound': 0.4588}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I just got a call from my boss - does he realise it's Saturday? :)\"\n",
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I just got a call from my boss - does he realise it's Saturday? ðŸ˜Š\"\n",
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why didn't it understand the emoji the same way it understood the emoticon? Well, **it only knows the words that it's been trained on,** and if VADER's never seen ðŸ˜Š before it won't know what to think of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextBlob\n",
    "\n",
    "TextBlob is built on top of NLTK, but is infinitely easier to use. It's still slow, but _it's so so so easy to use_. \n",
    "\n",
    "You can just feed TextBlob your sentence, then ask for a `.sentiment`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.275, subjectivity=0.8194444444444444)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"This restaurant was great, but I'm not sure if I'll go there again.\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How could it possibly be easier than that?!?!?** This time we get a `polarity` and a `subjectivity` instead of all of those different scores, but it's basically the same idea.\n",
    "\n",
    "If you like options: it turns out TextBlob actually has multiple sentiment analysis tools! How fun! We can plug in a different analyzer to get a different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.5879425317005774, p_neg=0.41205746829942275)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"This restaurant was great, but I'm not sure if I'll go there again.\", analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's a **very different result.** To understand why it's so different, we need to talk about where these sentiment numbers come from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But where do those numbers come from?\n",
    "\n",
    "The most important thing to understand is **sentiment is always just an opinion.** In this case it's an opinion, yes, but specifically **the opinion of a machine.**\n",
    "\n",
    "## VADER\n",
    "\n",
    "NLTK's Sentiment Intensity Analyzer works is using something called **VADER**, which is a list of words that have a sentiment associated with each of them.\n",
    "\n",
    "|Word|Sentiment rating|\n",
    "|---|---|\n",
    "|tragedy|-3.4|\n",
    "|rejoiced|2.0|\n",
    "|disaster|-3.1|\n",
    "|great|3.1|\n",
    "\n",
    "If you have more positives, the sentence is more positive. If you have more negatives, it's more negative. It can also take into account things like capitalization - you can read more about the classifier [here](http://t-redactyl.io/blog/2017/04/using-vader-to-handle-sentiment-analysis-with-social-media-text.html), or the actual paper it came out of [here](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf).\n",
    "\n",
    "**How do they know what's positive/negative?** They came up with a very big list of words, then asked people on the internet and paid them one cent for each word they scored.\n",
    "\n",
    "## TextBlob's `.sentiment`\n",
    "\n",
    "TextBlob's sentiment analysis is based on a separate library called [pattern](https://www.clips.uantwerpen.be/pattern).\n",
    "\n",
    "> The sentiment analysis lexicon bundled in Pattern focuses on adjectives. It contains adjectives that occur frequently in customer reviews, hand-tagged with values for polarity and subjectivity.\n",
    "\n",
    "Same kind of thing as NLTK's VADER, but it specifically looks at words from customer reviews.\n",
    "\n",
    "**How do they know what's positive/negative?** They look at (mostly) adjectives that occur in customer reviews and hand-tag them.\n",
    "\n",
    "## TextBlob's `.sentiment` + NaiveBayesAnalyzer\n",
    "\n",
    "TextBlob's other option uses a `NaiveBayesAnalyzer`, which is a machine learning technique. When you use this option with TextBlob, the sentiment is coming from \"an NLTK classifier trained on a movie reviews corpus.\"\n",
    "\n",
    "**How do they know what's positive/negative?** Looked at movie reviews and scores using machine learning, see what words are associated with a positive/negative rating.\n",
    "\n",
    "## What's this mean for me?\n",
    "\n",
    "When you're doing automatic sentiment analysis, you have two major questions: \n",
    "\n",
    "* Where does the list of known words come from\n",
    "* Where do the positive/negative scores come from\n",
    "\n",
    "Let's compare the tools we've used so far.\n",
    "\n",
    "|technique|word source|word selection|scores|\n",
    "|---|---|---|---|\n",
    "|NLTK (VADER)|everywhere|hand-picked|internet people, word-by-word|\n",
    "|TextBlob|product reviews|hand-picked, mostly adjectives|internet people, word-by-word|\n",
    "|TextBlob + NaiveBayesAnalyzer|movie reviews|all words|automatic based on score|\n",
    "\n",
    "A major thing that should jump out at you is **how different the sources are.**\n",
    "\n",
    "While VADER focuses on content found everywhere, TextBlob's two options are specific to certain domains. The [original paper for VADER](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf) passive-aggressively noted that VADER is effective at general use, but being trained on a specific domain can have benefits: \n",
    "\n",
    "> While some algorithms performed decently on test data from the specific domain for which it was expressly trained, they do not significantly outstrip the simple model we use.\n",
    "\n",
    "They're basically saying, \"if you train a model on words from a certain field, it will be good at that field.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "### Question 1: Is it okay to use a sentiment analyzer built on product reviews to check the sentiment of tweets? How about to check the sentiment of wine reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It might be a good idea to catch a trend, but not to make conclusions - specially on the internet, where language\n",
    "#and humor are based on changing the meaning of words and images (hence, memes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Is it okay to use a sentiment analyzer trained on everything to check the sentiment of tweets? How about to check the sentiment of wine reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as above "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: If I'm trying to report on whether people generally like or dislike what is happening throughout the Democratic debates, could I use these sorts of tools on tweets? Let's hear arguments for both sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It depends on too many variables, like the number of tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our own sentiment analyzer\n",
    "\n",
    "We don't want to rely on other people, we want to do this ourselves! There are two major ways to do sentiment analysis:\n",
    "\n",
    "* Have a list of words that you humans assign positive or negative scores to\n",
    "* Look at something scored (movie reviews, product reviews) and figure out which words appear with which scores\n",
    "\n",
    "Depending on how you look at it, it's either a classification or a regression problem. We'll see the difference down below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on tweets\n",
    "\n",
    "Let's say we were going to analyze the sentiment of tweets. If we had a list of tweets that were scored positive vs. negative, we could see which words are usually associated with positive scores and which are usually associated with negative scores.\n",
    "\n",
    "Luckily, we have **Sentiment140** - http://help.sentiment140.com/for-students - a list of 1.6 million tweets along with a score as to whether they're negative (0) or positive (4). We'll use it to build our own machine learning algorithm to see separate positivity from negativity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity          id                      datetime     query  \\\n",
       "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "          username                                            content  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = ['polarity', 'id', 'datetime', 'query', 'username', 'content']\n",
    "df = pd.read_csv(\"trainingandtestdata/training.1600000.processed.noemoticon.csv\", \n",
    "                 names=columns,\n",
    "                 encoding='latin-1')\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning our data\n",
    "\n",
    "The `polarity` field is whether something is positive or negative. How many do we have of each?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the documentation, `0` is negative and `4` is positive. Weird, right? Let's make it zero and one instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity'] = df.polarity.replace(4, 1, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm you have 800k of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a **lot of tweets.**\n",
    "\n",
    "Let's be honest: it's going to take our algorithms a long long time to process that many. Instead of working with our entire dataframe, let's use a **sample of 20,000**. If things are still slow before we can decrease this number.\n",
    "\n",
    "* **Tip:** `df.sample(5)` will give you a sample of 5 elements of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm you have 3000 rows and 6 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize our tweets\n",
    "\n",
    "Create a `TfidfVectorizer` and use it to vectorize our tweets. Since we don't have all the time in the world, we should probably use `max_features` to only take a selection of terms - how about 2000 for now?\n",
    "\n",
    "* **Tip:** Your end result should be a `words_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_commas(text):\n",
    "    pieces = text.split(\",\")\n",
    "    no_spaces = [piece.strip() for piece in pieces if piece]\n",
    "    return no_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>Â½s</th>\n",
       "      <th>Ã Â¹</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   10  100   11   12   13   14   15   16  ...  your  yours  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
       "\n",
       "   yourself  youtube   yr  yum  yummy  yup   Â½s   Ã Â¹  \n",
       "0       0.0      0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "1       0.0      0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "2       0.0      0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "3       0.0      0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "4       0.0      0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=2000)\n",
    "vectors = vectorizer.fit_transform(df.content)\n",
    "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your dataframe should look something like\n",
    "\n",
    "|00|000|10|...|your|...|yummy|yup|Â½t|\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "|0.0|0.0|0.0|...|0.0|...|0.0|0.0|0.0|\n",
    "|0.0|0.0|0.0|...|0.0|...|0.0|0.0|0.0|\n",
    "|0.0|0.0|0.0|...|0.235754|...|0.0|0.0|0.0|\n",
    "|0.0|0.0|0.0|...|0.0|...|0.0|0.0|0.0|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our algorithm\n",
    "\n",
    "### Setting up our variables\n",
    "\n",
    "Create an `X` and a `y`, same as ever. In this case, what are our **features** and what are our **labels?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>Â½s</th>\n",
       "      <th>Ã Â¹</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   10  100   11   12   13   14   15   16  ...  your  yours  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
       "\n",
       "   yourself  youtube   yr  yum  yummy  yup   Â½s   Ã Â¹  \n",
       "0       0.0      0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1 rows x 2000 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\",2000)\n",
    "words_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = words_df\n",
    "y = df.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that `X` has 20,000 rows and 2,000 columns, and that `y` has 3000 rows of 1 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking an algorithm\n",
    "\n",
    "What kind of algorithm do we want? We've used quite a few, and I just pulled another one couple classifiers of thin air."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When picking an algorithm, think about what the output should be: is it a category? A probability, an amount? In this case **it might be any of those!**\n",
    "\n",
    "For example:\n",
    "\n",
    "* **A category:** `0` or `1` for negative vs positive\n",
    "* **A probability:** The % chance that it's either negative or positive (between 0 and 1)\n",
    "* **An amount:** A score between 0 and 1 about how positive it is\n",
    "\n",
    "So hey, let's just make **one of each** of these. Name them `linreg`, `logreg`, `forest`, `svc`, and `bayes`.\n",
    "\n",
    "The two new ones - `LinearSVC` and `MultinomialNB` - work exactly the same as your other classifiers, you'll be doing the standard creation and fitting:\n",
    "\n",
    "```python\n",
    "svc = LinearSVC()\n",
    "svc.fit(X, y)\n",
    "```\n",
    "\n",
    "**Create and train classifiers in the cells below.** Add `%%time` to the top of each cell to see how long they take to train.\n",
    "\n",
    "* **Tip:** Remember you need to add `C=1e9` to logistic regression, and specify the solver!\n",
    "* **Tip:** If the logistic regression doesn't converge, it hasn't found an answer. You might need to increase `max_iter` (the default is 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.55 s, sys: 416 ms, total: 9.97 s\n",
      "Wall time: 5.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a linear regression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.7 s, sys: 364 ms, total: 36.1 s\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a logistic regression - if it doesn't converge be sure to increase max_iter\n",
    "logreg = LogisticRegression(C=1e9, solver='lbfgs', max_iter=1000)\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.99 s, sys: 149 ms, total: 7.14 s\n",
      "Wall time: 7.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a random forest classifier\n",
    "forest = RandomForestClassifier(n_estimators=10)\n",
    "forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 148 ms, sys: 5.33 ms, total: 154 ms\n",
      "Wall time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a linear support vector classifier (LinearSVC)\n",
    "svc = LinearSVC()\n",
    "svc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 110 ms, sys: 19.9 ms, total: 130 ms\n",
      "Wall time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a multinomial naive bayes classifier (MultinomialNB)\n",
    "bayes = MultinomialNB()\n",
    "bayes.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How long did each take to train?** How much faster were some compared to others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes was waaay fastest - but the ranged varied from ms to 30s "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use our models on some new data\n",
    "\n",
    "Now that we've trained our models, **they can try to predict whether a model is positive or negative**.\n",
    "\n",
    "**Add five more sentences to the list below.** They should be a mix of positive and negative. They can be boring, they can be exciting, they can be short, they can be long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm not sure how I feel about toast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you see the baseball game yesterday?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The package was delivered late and the contents were broken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trashy television shows are some of my favorites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm seeing a Kubrick film tomorrow, I hear not so great things about it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I find chirping birds irritating, but I know I'm not the only one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    content\n",
       "0                                       I'm not sure how I feel about toast\n",
       "1                                  Did you see the baseball game yesterday?\n",
       "2               The package was delivered late and the contents were broken\n",
       "3                          Trashy television shows are some of my favorites\n",
       "4  I'm seeing a Kubrick film tomorrow, I hear not so great things about it.\n",
       "5         I find chirping birds irritating, but I know I'm not the only one"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some test data\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "unknown = pd.DataFrame([\n",
    "       \"I'm not sure how I feel about toast\",\n",
    "       \"Did you see the baseball game yesterday?\",\n",
    "       \"The package was delivered late and the contents were broken\",\n",
    "       \"Trashy television shows are some of my favorites\",\n",
    "       \"I'm seeing a Kubrick film tomorrow, I hear not so great things about it.\",\n",
    "       \"I find chirping birds irritating, but I know I'm not the only one\"\n",
    "], columns=['content'])\n",
    "unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to **vectorizer** our sentences into numbers, so the algorithm can understand them.\n",
    "\n",
    "Our algorithm only knows **certain words.** Run `vectorizer.get_feature_names()` to show you the list of the words it knows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '10',\n",
       " '100',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '1st',\n",
       " '20',\n",
       " '2009',\n",
       " '21',\n",
       " '24',\n",
       " '25',\n",
       " '2day',\n",
       " '2nd',\n",
       " '30',\n",
       " '30am',\n",
       " '333',\n",
       " '3d',\n",
       " '3rd',\n",
       " '40',\n",
       " '45',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '5am',\n",
       " '60',\n",
       " '6am',\n",
       " '8am',\n",
       " '99',\n",
       " 'able',\n",
       " 'about',\n",
       " 'absolutely',\n",
       " 'ac',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'account',\n",
       " 'across',\n",
       " 'action',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'ages',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahaha',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'aim',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'alarm',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alex',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allen',\n",
       " 'allergies',\n",
       " 'allowed',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'america',\n",
       " 'american',\n",
       " 'amp',\n",
       " 'an',\n",
       " 'and',\n",
       " 'andy',\n",
       " 'angel',\n",
       " 'animal',\n",
       " 'ankle',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'apple',\n",
       " 'appreciate',\n",
       " 'are',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'argh',\n",
       " 'arm',\n",
       " 'around',\n",
       " 'arrived',\n",
       " 'art',\n",
       " 'article',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asleep',\n",
       " 'ass',\n",
       " 'at',\n",
       " 'ate',\n",
       " 'atl',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'august',\n",
       " 'australia',\n",
       " 'available',\n",
       " 'aw',\n",
       " 'awake',\n",
       " 'awards',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awsome',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'awwww',\n",
       " 'b4',\n",
       " 'babe',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'background',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'ball',\n",
       " 'band',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'barely',\n",
       " 'battery',\n",
       " 'bb',\n",
       " 'bbq',\n",
       " 'bc',\n",
       " 'bday',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'beer',\n",
       " 'before',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'bf',\n",
       " 'bff',\n",
       " 'bgt',\n",
       " 'big',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bill',\n",
       " 'bird',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bites',\n",
       " 'black',\n",
       " 'blackberry',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blast',\n",
       " 'bless',\n",
       " 'blink',\n",
       " 'blip',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blog',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'blue',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'body',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'books',\n",
       " 'booo',\n",
       " 'boots',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'both',\n",
       " 'bottle',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'boys',\n",
       " 'brain',\n",
       " 'brazil',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'breaking',\n",
       " 'bridge',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'british',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brunch',\n",
       " 'bsb',\n",
       " 'btw',\n",
       " 'buddy',\n",
       " 'bug',\n",
       " 'building',\n",
       " 'bummed',\n",
       " 'bummer',\n",
       " 'bunch',\n",
       " 'burnt',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butt',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'by',\n",
       " 'bye',\n",
       " 'ca',\n",
       " 'cab',\n",
       " 'cable',\n",
       " 'cake',\n",
       " 'cali',\n",
       " 'california',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'can',\n",
       " 'canada',\n",
       " 'cancelled',\n",
       " 'cancer',\n",
       " 'candy',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'cares',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catching',\n",
       " 'cats',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'cavs',\n",
       " 'cd',\n",
       " 'cell',\n",
       " 'center',\n",
       " 'challenge',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'charger',\n",
       " 'chat',\n",
       " 'chatting',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checking',\n",
       " 'cheer',\n",
       " 'cheers',\n",
       " 'cheese',\n",
       " 'chelsea',\n",
       " 'chicago',\n",
       " 'chicken',\n",
       " 'child',\n",
       " 'chillin',\n",
       " 'chilling',\n",
       " 'chinese',\n",
       " 'chips',\n",
       " 'chocolate',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'chris',\n",
       " 'chuck',\n",
       " 'church',\n",
       " 'city',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classic',\n",
       " 'clean',\n",
       " 'cleaning',\n",
       " 'clear',\n",
       " 'click',\n",
       " 'client',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'clothes',\n",
       " 'cloudy',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'co',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'cold',\n",
       " 'college',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'coming',\n",
       " 'comment',\n",
       " 'company',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'computer',\n",
       " 'concert',\n",
       " 'conference',\n",
       " 'confused',\n",
       " 'congrats',\n",
       " 'congratulations',\n",
       " 'connection',\n",
       " 'contact',\n",
       " 'content',\n",
       " 'contest',\n",
       " 'continue',\n",
       " 'control',\n",
       " 'cook',\n",
       " 'cooked',\n",
       " 'cookie',\n",
       " 'cookies',\n",
       " 'cooking',\n",
       " 'cool',\n",
       " 'copy',\n",
       " 'cos',\n",
       " 'couch',\n",
       " 'coughing',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'couldnt',\n",
       " 'count',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'cousin',\n",
       " 'cousins',\n",
       " 'cover',\n",
       " 'coz',\n",
       " 'crap',\n",
       " 'crappy',\n",
       " 'craving',\n",
       " 'crazy',\n",
       " 'cream',\n",
       " 'cried',\n",
       " 'cross',\n",
       " 'crowd',\n",
       " 'cruise',\n",
       " 'cry',\n",
       " 'crying',\n",
       " 'cup',\n",
       " 'cupcakes',\n",
       " 'curious',\n",
       " 'currently',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cutting',\n",
       " 'cuz',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'daddy',\n",
       " 'dads',\n",
       " 'daily',\n",
       " 'dallas',\n",
       " 'dammit',\n",
       " 'damn',\n",
       " 'dan',\n",
       " 'dance',\n",
       " 'dancing',\n",
       " 'dang',\n",
       " 'danny',\n",
       " 'dannymcfly',\n",
       " 'dark',\n",
       " 'darn',\n",
       " 'dat',\n",
       " 'data',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'dave',\n",
       " 'david',\n",
       " 'davidarchie',\n",
       " 'day',\n",
       " 'days',\n",
       " 'ddlovato',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'def',\n",
       " 'definitely',\n",
       " 'degrees',\n",
       " 'delete',\n",
       " 'delicious',\n",
       " 'demi',\n",
       " 'dentist',\n",
       " 'depressed',\n",
       " 'depressing',\n",
       " 'deserve',\n",
       " 'design',\n",
       " 'desk',\n",
       " 'desktop',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'died',\n",
       " 'diet',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'dinner',\n",
       " 'direct',\n",
       " 'dirty',\n",
       " 'disappointed',\n",
       " 'discovered',\n",
       " 'disney',\n",
       " 'dm',\n",
       " 'dnt',\n",
       " 'do',\n",
       " 'doc',\n",
       " 'doctor',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'dog',\n",
       " 'dogs',\n",
       " 'doin',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'done',\n",
       " 'donniewahlberg',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'doors',\n",
       " 'double',\n",
       " 'doubt',\n",
       " 'dougie',\n",
       " 'dougiemcfly',\n",
       " 'down',\n",
       " 'download',\n",
       " 'dr',\n",
       " 'drag',\n",
       " 'drama',\n",
       " 'draw',\n",
       " 'drawing',\n",
       " 'dream',\n",
       " 'dreams',\n",
       " 'dress',\n",
       " 'drink',\n",
       " 'drinking',\n",
       " 'drinks',\n",
       " 'drive',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'dropped',\n",
       " 'drunk',\n",
       " 'dry',\n",
       " 'dude',\n",
       " 'due',\n",
       " 'dumb',\n",
       " 'dunno',\n",
       " 'during',\n",
       " 'dvd',\n",
       " 'dying',\n",
       " 'e3',\n",
       " 'each',\n",
       " 'ear',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'ears',\n",
       " 'easier',\n",
       " 'east',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eating',\n",
       " 'ebay',\n",
       " 'editing',\n",
       " 'egg',\n",
       " 'eggs',\n",
       " 'eh',\n",
       " 'either',\n",
       " 'el',\n",
       " 'else',\n",
       " 'em',\n",
       " 'email',\n",
       " 'emails',\n",
       " 'empty',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'ending',\n",
       " 'energy',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enjoyed',\n",
       " 'enjoying',\n",
       " 'enough',\n",
       " 'entire',\n",
       " 'epic',\n",
       " 'episode',\n",
       " 'er',\n",
       " 'especially',\n",
       " 'essay',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'event',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyday',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everytime',\n",
       " 'everywhere',\n",
       " 'evil',\n",
       " 'exactly',\n",
       " 'exam',\n",
       " 'exams',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'excited',\n",
       " 'exciting',\n",
       " 'exercise',\n",
       " 'exhausted',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'extra',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'eyes',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'fact',\n",
       " 'fail',\n",
       " 'failed',\n",
       " 'fair',\n",
       " 'fake',\n",
       " 'fall',\n",
       " 'falling',\n",
       " 'fam',\n",
       " 'family',\n",
       " 'famous',\n",
       " 'fan',\n",
       " 'fans',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'farrah',\n",
       " 'fast',\n",
       " 'fat',\n",
       " 'father',\n",
       " 'fault',\n",
       " 'fav',\n",
       " 'fave',\n",
       " 'favorite',\n",
       " 'favourite',\n",
       " 'fb',\n",
       " 'fear',\n",
       " 'feel',\n",
       " 'feelin',\n",
       " 'feeling',\n",
       " 'feels',\n",
       " 'feet',\n",
       " 'fell',\n",
       " 'fellow',\n",
       " 'felt',\n",
       " 'festival',\n",
       " 'fever',\n",
       " 'few',\n",
       " 'ff',\n",
       " 'fight',\n",
       " 'fighting',\n",
       " 'figure',\n",
       " 'figured',\n",
       " 'fill',\n",
       " 'film',\n",
       " 'final',\n",
       " 'finale',\n",
       " 'finally',\n",
       " 'finals',\n",
       " 'find',\n",
       " 'finding',\n",
       " 'fine',\n",
       " 'fingers',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'fire',\n",
       " 'firefox',\n",
       " 'first',\n",
       " 'fish',\n",
       " 'fit',\n",
       " 'fix',\n",
       " 'fixed',\n",
       " 'flight',\n",
       " 'floor',\n",
       " 'flowers',\n",
       " 'flu',\n",
       " 'fly',\n",
       " 'flying',\n",
       " 'fm',\n",
       " 'fml',\n",
       " 'focus',\n",
       " 'folks',\n",
       " 'follow',\n",
       " 'follower',\n",
       " 'followers',\n",
       " 'followfriday',\n",
       " 'following',\n",
       " 'food',\n",
       " 'foot',\n",
       " 'for',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'forgot',\n",
       " 'form',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'four',\n",
       " 'france',\n",
       " 'freak',\n",
       " 'freakin',\n",
       " 'freaking',\n",
       " 'free',\n",
       " 'freedom',\n",
       " 'french',\n",
       " 'fresh',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'from',\n",
       " 'front',\n",
       " 'fruit',\n",
       " 'ftw',\n",
       " 'fuck',\n",
       " 'fuckin',\n",
       " 'fucking',\n",
       " 'full',\n",
       " 'fully',\n",
       " 'fun',\n",
       " 'funny',\n",
       " 'future',\n",
       " 'gah',\n",
       " 'game',\n",
       " 'games',\n",
       " 'garden',\n",
       " 'gave',\n",
       " 'gay',\n",
       " 'gd',\n",
       " 'general',\n",
       " 'german',\n",
       " 'germany',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'gettin',\n",
       " 'getting',\n",
       " 'gig',\n",
       " 'girl',\n",
       " 'girlfriend',\n",
       " 'girls',\n",
       " 'give',\n",
       " 'giving',\n",
       " 'glad',\n",
       " 'glass',\n",
       " 'go',\n",
       " 'goal',\n",
       " 'god',\n",
       " 'goes',\n",
       " 'goin',\n",
       " 'going',\n",
       " 'golf',\n",
       " 'gone',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'goodbye',\n",
       " 'goodnight',\n",
       " 'google',\n",
       " 'gorgeous',\n",
       " 'gosh',\n",
       " 'got',\n",
       " 'gotta',\n",
       " 'gotten',\n",
       " 'grad',\n",
       " 'graduation',\n",
       " 'grandma',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'green',\n",
       " 'grey',\n",
       " 'gross',\n",
       " 'group',\n",
       " 'growing',\n",
       " 'grrr',\n",
       " 'gt',\n",
       " 'gud',\n",
       " 'guess',\n",
       " 'guitar',\n",
       " 'gunna',\n",
       " 'gutted',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'gym',\n",
       " 'ha',\n",
       " 'had',\n",
       " 'hadn',\n",
       " 'hah',\n",
       " 'haha',\n",
       " 'hahah',\n",
       " 'hahaha',\n",
       " 'hahahaha',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'handle',\n",
       " 'hands',\n",
       " 'hang',\n",
       " 'hanging',\n",
       " 'hangover',\n",
       " 'hannah',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'happens',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'harder',\n",
       " 'hardly',\n",
       " 'harry',\n",
       " 'has',\n",
       " 'hasn',\n",
       " 'hat',\n",
       " 'hate',\n",
       " 'hates',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'havent',\n",
       " 'havin',\n",
       " 'having',\n",
       " 'hayfever',\n",
       " 'he',\n",
       " 'head',\n",
       " 'headache',\n",
       " 'headed',\n",
       " 'heading',\n",
       " 'healthy',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'hearing',\n",
       " 'heart',\n",
       " 'heat',\n",
       " 'heaven',\n",
       " 'heavy',\n",
       " 'heh',\n",
       " 'hehe',\n",
       " 'hehehe',\n",
       " 'hell',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'helped',\n",
       " 'helping',\n",
       " 'helps',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hes',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'hilarious',\n",
       " 'hills',\n",
       " 'him',\n",
       " 'his',\n",
       " 'history',\n",
       " 'hit',\n",
       " 'hmm',\n",
       " 'hmmm',\n",
       " 'hold',\n",
       " 'holiday',\n",
       " 'holidays',\n",
       " 'holy',\n",
       " 'home',\n",
       " 'homemade',\n",
       " 'homework',\n",
       " 'honey',\n",
       " 'hope',\n",
       " 'hopefully',\n",
       " 'hoping',\n",
       " 'horrible',\n",
       " 'horse',\n",
       " 'hospital',\n",
       " 'hot',\n",
       " 'hotel',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hows',\n",
       " 'hrs',\n",
       " 'http',\n",
       " 'hubby',\n",
       " 'hug',\n",
       " 'huge',\n",
       " 'hugs',\n",
       " 'huh',\n",
       " 'human',\n",
       " 'hun',\n",
       " 'hungover',\n",
       " 'hungry',\n",
       " 'hurry',\n",
       " 'hurt',\n",
       " 'hurting',\n",
       " 'hurts',\n",
       " 'husband',\n",
       " 'ice',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'ideas',\n",
       " 'idk',\n",
       " 'idol',\n",
       " 'if',\n",
       " 'ill',\n",
       " 'ily',\n",
       " 'im',\n",
       " 'ima',\n",
       " 'image',\n",
       " 'imagine',\n",
       " 'imma',\n",
       " 'important',\n",
       " 'impressed',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'info',\n",
       " 'inside',\n",
       " 'instead',\n",
       " 'interested',\n",
       " 'interesting',\n",
       " 'internet',\n",
       " 'interview',\n",
       " 'into',\n",
       " 'invite',\n",
       " 'iphone',\n",
       " 'ipod',\n",
       " 'ireland',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'isnt',\n",
       " 'issue',\n",
       " 'issues',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itunes',\n",
       " 'ive',\n",
       " 'iÃ¢',\n",
       " 'jack',\n",
       " 'jay',\n",
       " 'jb',\n",
       " 'jealous',\n",
       " 'jesus',\n",
       " 'jk',\n",
       " 'job',\n",
       " 'joe',\n",
       " 'john',\n",
       " 'join',\n",
       " 'joined',\n",
       " 'joke',\n",
       " 'jon',\n",
       " 'jonas',\n",
       " 'jonasbrothers',\n",
       " 'jordanknight',\n",
       " 'joy',\n",
       " 'juice',\n",
       " 'july',\n",
       " 'jump',\n",
       " 'june',\n",
       " 'jus',\n",
       " 'just',\n",
       " 'justin',\n",
       " 'kate',\n",
       " 'keep',\n",
       " 'keeping',\n",
       " 'keeps',\n",
       " 'keys',\n",
       " 'kick',\n",
       " 'kicked',\n",
       " 'kid',\n",
       " 'kidding',\n",
       " 'kids',\n",
       " 'kill',\n",
       " 'killed',\n",
       " 'killing',\n",
       " 'kind',\n",
       " 'kinda',\n",
       " 'king',\n",
       " 'kiss',\n",
       " 'kitchen',\n",
       " 'kitten',\n",
       " 'kitty',\n",
       " 'knee',\n",
       " 'knew',\n",
       " 'kno',\n",
       " 'know',\n",
       " 'knowing',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'kris',\n",
       " 'la',\n",
       " 'lack',\n",
       " 'ladies',\n",
       " 'lady',\n",
       " 'lake',\n",
       " 'lakers',\n",
       " 'lame',\n",
       " 'language',\n",
       " 'laptop',\n",
       " 'large',\n",
       " 'last',\n",
       " 'late',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'laugh',\n",
       " 'laughing',\n",
       " 'launch',\n",
       " 'laundry',\n",
       " 'law',\n",
       " 'lay',\n",
       " 'laying',\n",
       " 'lazy',\n",
       " 'le',\n",
       " 'learn',\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually when we use the vectorizer, we write code like this:\n",
    "    \n",
    "```python\n",
    "vectors = vectorizer.fit_transform(....)\n",
    "```\n",
    "\n",
    "Which both learns all the words **and** counts them. In this case **we already have the list of words we know, we only want to count them.** So instead of `.fit_transform`, we just use `.transform`:\n",
    "\n",
    "```python\n",
    "unknown_vectors = vectorizer.transform(unknown.content)\n",
    "unknown_words_df = ......\n",
    "```\n",
    "\n",
    "Finish making your `unknown_words_df` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_vectors = vectorizer.transform(unknown.content)\n",
    "unknown_words_df = pd.DataFrame(unknown_vectors.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm `unknown_words_df` is 11 rows and 2,000 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_words_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with our models\n",
    "\n",
    "To make a prediction for each of our sentences, you can use `.predict` with each of our models. For example, it would look like this for linear regression:\n",
    "\n",
    "```python\n",
    "unknown['pred_linreg'] = linreg.predict(unknown_words_df)\n",
    "```\n",
    "\n",
    "To add the prediction for logistic regression, you'd run similar `.predict` code, which will give you a `0` (negative) or a `1` (positive). A difference between the two is that for logistic regression, you can **also ask for the probability that the sentence is in the `1` category** instead of just simply the category. To do that, you use this code:\n",
    "\n",
    "```python\n",
    "unknown['pred_logreg_prob'] = linreg.predict_proba(unknown_words_df)[:,1]\n",
    "```\n",
    "\n",
    "**Add new columns for each of the models you trained.** If the model has a `.predict_proba`, add that as a column as well. \n",
    "\n",
    "* **Tip:** Tab is helpful for knowing whether `.predict_proba` is an option.\n",
    "* **Tip:** Don't forget the `[:,1]` after `.predict_proba`, it means \"give me the probability for category `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown['pred_linreg'] = linreg.predict(unknown_words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown['pred_logreg'] = logreg.predict(unknown_words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown['pred_logreg_proba'] = logreg.predict_proba(unknown_words_df)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown['pred_bayes'] = bayes.predict(unknown_words_df)\n",
    "unknown['pred_bayes_prob'] = bayes.predict_proba(unknown_words_df)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown['pred_svc'] = svc.predict(unknown_words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>pred_linreg</th>\n",
       "      <th>pred_logreg</th>\n",
       "      <th>pred_logreg_proba</th>\n",
       "      <th>pred_bayes</th>\n",
       "      <th>pred_bayes_prob</th>\n",
       "      <th>pred_svc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm not sure how I feel about toast</td>\n",
       "      <td>0.491781</td>\n",
       "      <td>0</td>\n",
       "      <td>0.489460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you see the baseball game yesterday?</td>\n",
       "      <td>0.468759</td>\n",
       "      <td>0</td>\n",
       "      <td>0.426485</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The package was delivered late and the contents were broken</td>\n",
       "      <td>0.161951</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.321146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trashy television shows are some of my favorites</td>\n",
       "      <td>0.432031</td>\n",
       "      <td>0</td>\n",
       "      <td>0.288918</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm seeing a Kubrick film tomorrow, I hear not so great things about it.</td>\n",
       "      <td>0.531601</td>\n",
       "      <td>0</td>\n",
       "      <td>0.496921</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    content  \\\n",
       "0                                       I'm not sure how I feel about toast   \n",
       "1                                  Did you see the baseball game yesterday?   \n",
       "2               The package was delivered late and the contents were broken   \n",
       "3                          Trashy television shows are some of my favorites   \n",
       "4  I'm seeing a Kubrick film tomorrow, I hear not so great things about it.   \n",
       "\n",
       "   pred_linreg  pred_logreg  pred_logreg_proba  pred_bayes  pred_bayes_prob  \\\n",
       "0     0.491781            0           0.489460           0         0.487722   \n",
       "1     0.468759            0           0.426485           1         0.524916   \n",
       "2     0.161951            0           0.127143           0         0.321146   \n",
       "3     0.432031            0           0.288918           1         0.518611   \n",
       "4     0.531601            0           0.496921           1         0.588909   \n",
       "\n",
       "   pred_svc  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown['pred_forest'] = forest.predict(unknown_words_df)\n",
    "unknown['pred_forest_prob'] = forest.predict_proba(unknown_words_df)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>pred_linreg</th>\n",
       "      <th>pred_logreg</th>\n",
       "      <th>pred_logreg_proba</th>\n",
       "      <th>pred_bayes</th>\n",
       "      <th>pred_bayes_prob</th>\n",
       "      <th>pred_svc</th>\n",
       "      <th>pred_forest</th>\n",
       "      <th>pred_forest_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm not sure how I feel about toast</td>\n",
       "      <td>0.491781</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48946</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               content  pred_linreg  pred_logreg  \\\n",
       "0  I'm not sure how I feel about toast     0.491781            0   \n",
       "\n",
       "   pred_logreg_proba  pred_bayes  pred_bayes_prob  pred_svc  pred_forest  \\\n",
       "0            0.48946           0         0.487722         0            1   \n",
       "\n",
       "   pred_forest_prob  \n",
       "0               0.6  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look something like the below. Check your column names to confirm they match up.\n",
    "\n",
    "|content|pred_linreg|pred_logreg|pred_logreg_proba|pred_forest|pred_forest_proba|pred_svc|pred_bayes|pred_bayes_proba|\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "|I'm not sure how I feel about toast|0.342560|0|0.271403|0|0.5|0|0|0.425271|\n",
    "|...|...|...|...|...|...|...|...|...|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: What do the numbers mean? What's the difference between a 0 and a 1? A 0.5? Negative numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The chance of the number be + or - and the probability that the sentence is in the 1 category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Were there any sentences where the classifiers seemed to disagree about? How do you feel about the amount they disagree? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>pred_linreg</th>\n",
       "      <th>pred_logreg</th>\n",
       "      <th>pred_logreg_proba</th>\n",
       "      <th>pred_bayes</th>\n",
       "      <th>pred_bayes_prob</th>\n",
       "      <th>pred_svc</th>\n",
       "      <th>pred_forest</th>\n",
       "      <th>pred_forest_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm not sure how I feel about toast</td>\n",
       "      <td>0.491781</td>\n",
       "      <td>0</td>\n",
       "      <td>0.489460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you see the baseball game yesterday?</td>\n",
       "      <td>0.468759</td>\n",
       "      <td>0</td>\n",
       "      <td>0.426485</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524916</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The package was delivered late and the contents were broken</td>\n",
       "      <td>0.161951</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.321146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trashy television shows are some of my favorites</td>\n",
       "      <td>0.432031</td>\n",
       "      <td>0</td>\n",
       "      <td>0.288918</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm seeing a Kubrick film tomorrow, I hear not so great things about it.</td>\n",
       "      <td>0.531601</td>\n",
       "      <td>0</td>\n",
       "      <td>0.496921</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588909</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I find chirping birds irritating, but I know I'm not the only one</td>\n",
       "      <td>-0.080431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027955</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    content  \\\n",
       "0                                       I'm not sure how I feel about toast   \n",
       "1                                  Did you see the baseball game yesterday?   \n",
       "2               The package was delivered late and the contents were broken   \n",
       "3                          Trashy television shows are some of my favorites   \n",
       "4  I'm seeing a Kubrick film tomorrow, I hear not so great things about it.   \n",
       "5         I find chirping birds irritating, but I know I'm not the only one   \n",
       "\n",
       "   pred_linreg  pred_logreg  pred_logreg_proba  pred_bayes  pred_bayes_prob  \\\n",
       "0     0.491781            0           0.489460           0         0.487722   \n",
       "1     0.468759            0           0.426485           1         0.524916   \n",
       "2     0.161951            0           0.127143           0         0.321146   \n",
       "3     0.432031            0           0.288918           1         0.518611   \n",
       "4     0.531601            0           0.496921           1         0.588909   \n",
       "5    -0.080431            0           0.027955           0         0.259807   \n",
       "\n",
       "   pred_svc  pred_forest  pred_forest_prob  \n",
       "0         0            1               0.6  \n",
       "1         0            1               0.7  \n",
       "2         0            0               0.5  \n",
       "3         0            0               0.2  \n",
       "4         1            1               0.6  \n",
       "5         0            0               0.2  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown\n",
    "#Some of the predictions are a bit off, like in the 5th sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: What's the difference between using a 0/1 to talk about sentiment compared to 0-1? When might you use one compared to another?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0/1 shows if something is negative or positive, 0-1 is about the percentage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: What's the difference between the linear regression model and the other models we're using? Why might it fit or not fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: Between 0-1, what range do you think counts as \"negative,\" \"positive\" and \"neutral\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: Does the variation in scores reflect the variation you would see among people? Or is it better or worse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maybe we should have tested this?\n",
    "\n",
    "We can actually see **which model performs the best**. Let's remind ourselves what we have by looking at:\n",
    "\n",
    "* `X`\n",
    "* `y`\n",
    "* `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>Â½s</th>\n",
       "      <th>Ã Â¹</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   10  100   11   12   13   14   15   16  ...  your  yours  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
       "\n",
       "   yourself  youtube   yr  yum  yummy  yup   Â½s   Ã Â¹  \n",
       "0       0.0      0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "1       0.0      0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "2       0.0      0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "3       0.0      0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "4       0.0      0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414745    0\n",
       "355574    0\n",
       "182981    0\n",
       "599193    0\n",
       "648006    0\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414745</th>\n",
       "      <td>0</td>\n",
       "      <td>2060898558</td>\n",
       "      <td>Sat Jun 06 19:47:36 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>marybeary2</td>\n",
       "      <td>Missed my bf today  hope he had a good day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355574</th>\n",
       "      <td>0</td>\n",
       "      <td>2043969168</td>\n",
       "      <td>Fri Jun 05 08:40:47 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>DishofSalt</td>\n",
       "      <td>So excited to be invited the True Blood premiere party next week. So sad I can't actually go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182981</th>\n",
       "      <td>0</td>\n",
       "      <td>1967313657</td>\n",
       "      <td>Fri May 29 19:21:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Jaimie074</td>\n",
       "      <td>@monimenudo08 Nah but dat did get me more down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599193</th>\n",
       "      <td>0</td>\n",
       "      <td>2220615525</td>\n",
       "      <td>Thu Jun 18 03:32:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>eurini</td>\n",
       "      <td>TITWANK! Just stood on a plug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648006</th>\n",
       "      <td>0</td>\n",
       "      <td>2236910231</td>\n",
       "      <td>Fri Jun 19 04:48:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>cidermaker</td>\n",
       "      <td>Not a Britney in sight. Woe is me!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        polarity          id                      datetime     query  \\\n",
       "414745         0  2060898558  Sat Jun 06 19:47:36 PDT 2009  NO_QUERY   \n",
       "355574         0  2043969168  Fri Jun 05 08:40:47 PDT 2009  NO_QUERY   \n",
       "182981         0  1967313657  Fri May 29 19:21:12 PDT 2009  NO_QUERY   \n",
       "599193         0  2220615525  Thu Jun 18 03:32:18 PDT 2009  NO_QUERY   \n",
       "648006         0  2236910231  Fri Jun 19 04:48:07 PDT 2009  NO_QUERY   \n",
       "\n",
       "          username  \\\n",
       "414745  marybeary2   \n",
       "355574  DishofSalt   \n",
       "182981   Jaimie074   \n",
       "599193      eurini   \n",
       "648006  cidermaker   \n",
       "\n",
       "                                                                                              content  \n",
       "414745                                                     Missed my bf today  hope he had a good day  \n",
       "355574  So excited to be invited the True Blood premiere party next week. So sad I can't actually go   \n",
       "182981                                                @monimenudo08 Nah but dat did get me more down   \n",
       "599193                                                                 TITWANK! Just stood on a plug   \n",
       "648006                                                            Not a Britney in sight. Woe is me!   "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original dataframe is a list of many, many tweets. We turned this into `X` - vectorized words - and `y` - whether the tweet is negative or positive.\n",
    "\n",
    "Before we used `.fit(X, y)` to train on all of our data. Instead, **we can test our models** by doing a test/train split and see if the predictions match the actual labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test and training data \n",
    "\n",
    "Split your `X` and `y` into train and test datasets. I always have to look up how to do it, so here's the code for you:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `X_train` and `y_train` to train all your models, except the linear regression one. You should be training:\n",
    "\n",
    "* `logreg`\n",
    "* `forest`\n",
    "* `svc`\n",
    "* `bayes`\n",
    "\n",
    "Again, do them each in **separate cells** and use `%%time` to see how long each one takes to learn what's a positive vs negative tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.5 s, sys: 737 ms, total: 46.3 s\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logreg = LogisticRegression(C=1e9, solver='lbfgs', max_iter=1000)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.83 s, sys: 120 ms, total: 4.95 s\n",
      "Wall time: 5.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forest = RandomForestClassifier(n_estimators=10)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svc = LinearSVC()\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bayes = MultinomialNB()\n",
    "bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices\n",
    "\n",
    "To see how well they did, we'll use a confusion matrix for each one. For example, here is what you'll use for logistic regression:\n",
    "\n",
    "```python\n",
    "y_true = y_test\n",
    "y_pred = logreg.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>1798</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>618</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                1798                 709\n",
       "Is positive                 618                1875"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = logreg.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>1873</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>842</td>\n",
       "      <td>1651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                1873                 634\n",
       "Is positive                 842                1651"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = forest.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>2002</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>431</td>\n",
       "      <td>2062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                2002                 505\n",
       "Is positive                 431                2062"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = svc.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>1967</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>544</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                1967                 540\n",
       "Is positive                 544                1949"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = bayes.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage-based confusion matrices\n",
    "\n",
    "Those are kind of irritating in that they're just numbers. It might work better if you do something like this instead to get percentages:\n",
    "\n",
    "```python\n",
    "y_true = y_test\n",
    "y_pred = logreg.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names) / matrix.sum(axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.717192</td>\n",
       "      <td>0.284396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.246510</td>\n",
       "      <td>0.752106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.717192            0.284396\n",
       "Is positive            0.246510            0.752106"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = logreg.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names) / matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.747108</td>\n",
       "      <td>0.254312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.335860</td>\n",
       "      <td>0.662254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.747108            0.254312\n",
       "Is positive            0.335860            0.662254"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = forest.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names) / matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.798564</td>\n",
       "      <td>0.202567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.171919</td>\n",
       "      <td>0.827116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.798564            0.202567\n",
       "Is positive            0.171919            0.827116"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = svc.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names) / matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.784603</td>\n",
       "      <td>0.216606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.216992</td>\n",
       "      <td>0.781789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.784603            0.216606\n",
       "Is positive            0.216992            0.781789"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = bayes.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names) / matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10: Which models performed the best? Were there big differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC and Bayes performed best. No big differences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11: Do you think it's more important to be sensitive to negativity or positivity? Do we want more positive things incorrectly marked as negative, or more negative things marked as positive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I feel that it depends on the subject... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12: They all had very different training times. Which ones offer the best combination of performance and not making you wait around for an hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again, SVC and Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13: If you have a decent algorithm that trains more quickly, that could that mean about feature selection or the size of your training set? Why did we use `max_features=` and `df.sample`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To not waste time haha  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14: How do you feel about sentiment analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It could be useful, but I don't see myself applying it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15: How do you feel about [this piece from the UpShot](https://www.nytimes.com/interactive/2017/02/28/upshot/trump-sounds-different-tone-in-first-address-to-congress.html) that uses [the Emotional Lexicon](http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16: What would you feel comfortable using our sentiment classifier for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
